{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率： 0.7712483399734396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/stochastic_gradient.py:603: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# 1. 读取数据\n",
    "# 2. 扔掉 nan\n",
    "# 3. wage 转为 0 / 1\n",
    "# 4. 分割出 x y\n",
    "# 5. object 转为 数值型\n",
    "# 6. one-hot\n",
    "# 7. 标准化\n",
    "# 8. perceptron\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class Dataset(object):\n",
    "\tdef __init__(self, train_x, train_y, test_x, test_y):\n",
    "\t\tself.train_x = train_x\n",
    "\t\tself.train_y = train_y\n",
    "\t\tself.test_x = test_x\n",
    "\t\tself.test_y = test_y\n",
    "\t\tself.pred_y = None\n",
    "\n",
    "\tdef print_info(self):\n",
    "\t\tprint(self.train_x)\n",
    "\t\tprint(self.train_y)\n",
    "\t\tprint(self.test_x)\n",
    "\t\tprint(self.test_y)\n",
    "\t\tprint(self.pred_y)\n",
    "\n",
    "\n",
    "class FeatureEngineer(object):\n",
    "\tdef __init__(self):\n",
    "\t\t# https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names\n",
    "\t\tnames = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'wage']\n",
    "\t\tself.names = names\n",
    "\n",
    "\t\t# read_csv 的参数介绍\n",
    "\t\t# https://www.cnblogs.com/datablog/p/6127000.html\n",
    "\t\t# https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\n",
    "\t\t# \n",
    "\t\t# header=None, names=names, 数据集没有表头, 我们手动加上标题信息 names\n",
    "\t\t# na_values 训练集以及测试集中的缺失值用 ? 表示\n",
    "\t\ttrain_set = pd.read_csv('adult.data', header=None, names=names, sep=', ', na_values=[\"?\"], engine='python')\n",
    "\n",
    "\t\t# test 数据集第一行是多余的, 所以skiprows=1\n",
    "\t\ttest_set = pd.read_csv('adult.test', header=None, names=names, sep=', ', na_values=[\"?\"], engine='python', skiprows=1).dropna()\n",
    "\n",
    "\t\t# 如果某一行数据有缺失值, 那就删除这一行\n",
    "\t\ttrain_set = train_set.dropna()\n",
    "\t\ttest_set = test_set.dropna()\n",
    "\n",
    "\t\t# 将训练集的 \"<=50K\" 转为标签 0, \">50K\" 转为标签 1\n",
    "\t\ttrain_set['wage'] = train_set['wage'].replace({'<=50K': 0, '>50K': 1})\n",
    "\t\t# 测试集中的 \"<=50K.\" 转为标签 0, \">50K.\" 转为标签 1\n",
    "\t\ttest_set['wage'] = test_set['wage'].replace({'<=50K.': 0, '>50K.': 1})\n",
    "\n",
    "\t\tself.train_set = train_set\n",
    "\t\tself.test_set = test_set\n",
    "\n",
    "\tdef filter1(self):\n",
    "\t\t'''\n",
    "\t\tfilter1 仅保留数值型特征\n",
    "\t\tTODO:\n",
    "\t\tint to float to rm warnings given by StandardScaler()\n",
    "\t\t'''\n",
    "\n",
    "\t\ttrain_set = self.train_set\n",
    "\t\ttest_set = self.test_set\n",
    "\n",
    "\t\ttrain_y = train_set['wage']\n",
    "\t\ttrain_set.pop('wage')\n",
    "\t\ttrain_set.pop('workclass')\n",
    "\t\ttrain_set.pop('education')\n",
    "\t\ttrain_set.pop('marital-status')\n",
    "\t\ttrain_set.pop('occupation')\n",
    "\t\ttrain_set.pop('relationship')\n",
    "\t\ttrain_set.pop('race')\n",
    "\t\ttrain_set.pop('sex')\n",
    "\t\ttrain_set.pop('native-country')\n",
    "\t\ttrain_x = train_set\n",
    "\n",
    "\t\ttest_y = test_set['wage']\n",
    "\t\ttest_set.pop('wage')\n",
    "\t\ttest_set.pop('workclass')\n",
    "\t\ttest_set.pop('education')\n",
    "\t\ttest_set.pop('marital-status')\n",
    "\t\ttest_set.pop('occupation')\n",
    "\t\ttest_set.pop('relationship')\n",
    "\t\ttest_set.pop('race')\n",
    "\t\ttest_set.pop('sex')\n",
    "\t\ttest_set.pop('native-country')\n",
    "\t\ttest_x = test_set\n",
    "\n",
    "\t\tself.train_x = train_x\n",
    "\t\tself.train_y = train_y\n",
    "\t\tself.test_x = test_x\n",
    "\t\tself.test_y = test_y\n",
    "\n",
    "\tdef filter2(self):\n",
    "\t\t'''\n",
    "\t\tTODO:\n",
    "\t\t1. keep more features\n",
    "\t\t2. merge train and test, then use one-hot, finally split back into train and test\n",
    "\t\t'''\n",
    "\t\tpass\n",
    "\n",
    "\tdef standardize(self):\n",
    "\t\tfrom sklearn.preprocessing import StandardScaler\n",
    "\t\tss = StandardScaler()\n",
    "\t\tself.train_x = ss.fit_transform(self.train_x)\n",
    "\t\tself.test_x = ss.fit_transform(self.test_x)\n",
    "\n",
    "\tdef get_dataset(self):\n",
    "\t\tself.dataset = Dataset(self.train_x, self.train_y, self.test_x, self.test_y)\n",
    "\t\treturn self.dataset\n",
    "\n",
    "def test1():\n",
    "\tfe = FeatureEngineer()\n",
    "\tfe.filter1()\n",
    "\tfe.standardize()\n",
    "\tdataset = fe.get_dataset()\n",
    "\n",
    "\tfrom sklearn.linear_model import Perceptron\n",
    "\tperceptron = Perceptron(max_iter = 1, eta0 = 0.01, tol = 1e-3, random_state = 0)\n",
    "\tperceptron.fit(dataset.train_x, dataset.train_y)\n",
    "\tpred_y = perceptron.predict(dataset.test_x).tolist()\n",
    "\tdataset.pred_y = pred_y\n",
    "\n",
    "\tfrom sklearn.metrics import accuracy_score\n",
    "\tprint(\"准确率：\", accuracy_score(dataset.test_y, dataset.pred_y))\n",
    "\n",
    "test1()\n",
    "\n",
    "\n",
    "'''\n",
    "结果分析:\n",
    "虽然丢掉了很多数据，但是准确率和原来没有丢掉数据相比，并没有太大变化(甚至有提升)\n",
    "通过阅读 adult.names 文档可以知道, 训练集的标签分布是【不均匀的】, 0 的比例是 76.07%, 1 的比例是 23.93%\n",
    "测试集的标签也有类似的分布, 0 的比例是 75.22%, 1 的比例是 24.78%\n",
    "与本次特征工程+模型给出的 77.12% 的准确率很接近\n",
    "也就是说, 如果一个模型 model 在任何时候都输出 0, 那这个 model 在测试集上的准确率也会有 75% 左右的准确率\n",
    "\n",
    "本次实验, 首要目的是熟悉过程, 接下来是进一步的改进\n",
    "TODO1: filter1\n",
    "TODO2: filter2\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
