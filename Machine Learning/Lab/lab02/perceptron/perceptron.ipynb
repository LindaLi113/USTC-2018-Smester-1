{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率:  0.7739043824701195\n"
     ]
    }
   ],
   "source": [
    "# 1. 读取数据\n",
    "# 2. 扔掉 nan\n",
    "# 3. wage 转为 0 / 1\n",
    "# 4. 分割出 x y\n",
    "# 5. object 转为 数值型\n",
    "# 6. one-hot\n",
    "# 7. 标准化\n",
    "# 8. perceptron\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# https://stackoverflow.com/questions/33572118/stop-jupyter-notebook-from-printing-warnings-status-updates-to-terminal?lq=1\n",
    "import warnings;\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "class Dataset(object):\n",
    "\tdef __init__(self, train_x, train_y, test_x, test_y):\n",
    "\t\tself.train_x = train_x\n",
    "\t\tself.train_y = train_y\n",
    "\t\tself.test_x = test_x\n",
    "\t\tself.test_y = test_y\n",
    "\t\tself.pred_y = None\n",
    "\n",
    "\tdef print_info(self):\n",
    "\t\tprint(self.train_x)\n",
    "\t\tprint(self.train_y)\n",
    "\t\tprint(self.test_x)\n",
    "\t\tprint(self.test_y)\n",
    "\t\tprint(self.pred_y)\n",
    "\n",
    "class FeatureEngineer(object):\n",
    "\tdef __init__(self):\n",
    "\t\t# https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names\n",
    "\t\tnames = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'wage']\n",
    "\t\tself.names = names\n",
    "\n",
    "\t\t# read_csv 的参数介绍\n",
    "\t\t# https://www.cnblogs.com/datablog/p/6127000.html\n",
    "\t\t# https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\n",
    "\t\t# \n",
    "\t\t# header=None, names=names, 数据集没有表头, 我们手动加上标题信息 names\n",
    "\t\t# na_values 训练集以及测试集中的缺失值用 ? 表示\n",
    "\t\ttrain_set = pd.read_csv('adult.data', header=None, names=names, sep=', ', na_values=[\"?\"], engine='python')\n",
    "\n",
    "\t\t# test 数据集第一行是多余的, 所以skiprows=1\n",
    "\t\ttest_set = pd.read_csv('adult.test', header=None, names=names, sep=', ', na_values=[\"?\"], engine='python', skiprows=1)\n",
    "\n",
    "\t\t# 如果某一行数据有缺失值, 那就删除这一行\n",
    "\t\t# 注意 dropna() 不会将下一行的行号提前\n",
    "\t\t# 比如 train_set 第 15 条记录存在 ？\n",
    "\t\t# dropna 之后第 16 条记录不会变成第 15 条记录\n",
    "\t\t# 而是把记录 15 标记为空白。。。\n",
    "\t\t# 所以不能直接用 for i in range(row) 的方式遍历 pd 数据集\n",
    "\t\ttrain_set = train_set.dropna()\n",
    "\t\ttest_set = test_set.dropna()\n",
    "\n",
    "\t\t# 需要 reset_index(drop=True, inplace=True), 将无效的记录去掉\n",
    "\t\t# https://stackoverflow.com/questions/40755680/how-to-reset-index-pandas-dataframe-after-dropna-pandas-dataframe\n",
    "\t\ttrain_set.reset_index(drop=True, inplace=True)\n",
    "\t\ttest_set.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\t\t# 将训练集的 \"<=50K\" 转为标签 0, \">50K\" 转为标签 1\n",
    "\t\ttrain_set['wage'] = train_set['wage'].replace({'<=50K': -1, '>50K': 1})\n",
    "\t\t# 测试集中的 \"<=50K.\" 转为标签 0, \">50K.\" 转为标签 1\n",
    "\t\ttest_set['wage'] = test_set['wage'].replace({'<=50K.': -1, '>50K.': 1})\n",
    "\n",
    "\t\tself.train_set = train_set\n",
    "\t\tself.test_set = test_set\n",
    "\n",
    "\tdef filter1(self):\n",
    "\t\t'''\n",
    "\t\tfilter1 仅保留数值型特征\n",
    "\t\tTODO:\n",
    "\t\tint to float to rm warnings given by StandardScaler()\n",
    "\t\t'''\n",
    "\n",
    "\t\ttrain_set = self.train_set\n",
    "\t\ttest_set = self.test_set\n",
    "\n",
    "\t\ttrain_y = train_set['wage']\n",
    "\t\ttrain_set.pop('wage')\n",
    "\t\ttrain_set.pop('workclass')\n",
    "\t\ttrain_set.pop('education')\n",
    "\t\ttrain_set.pop('marital-status')\n",
    "\t\ttrain_set.pop('occupation')\n",
    "\t\ttrain_set.pop('relationship')\n",
    "\t\ttrain_set.pop('race')\n",
    "\t\ttrain_set.pop('sex')\n",
    "\t\ttrain_set.pop('native-country')\n",
    "\t\ttrain_x = train_set\n",
    "\n",
    "\t\ttest_y = test_set['wage']\n",
    "\t\ttest_set.pop('wage')\n",
    "\t\ttest_set.pop('workclass')\n",
    "\t\ttest_set.pop('education')\n",
    "\t\ttest_set.pop('marital-status')\n",
    "\t\ttest_set.pop('occupation')\n",
    "\t\ttest_set.pop('relationship')\n",
    "\t\ttest_set.pop('race')\n",
    "\t\ttest_set.pop('sex')\n",
    "\t\ttest_set.pop('native-country')\n",
    "\t\ttest_x = test_set\n",
    "\n",
    "\t\tself.train_x = train_x\n",
    "\t\tself.train_y = train_y\n",
    "\t\tself.test_x = test_x\n",
    "\t\tself.test_y = test_y\n",
    "\t\t# print(train_x.head(20))\n",
    "\t\t# print(train_y.head(20))\n",
    "\n",
    "\tdef filter2(self):\n",
    "\t\t'''\n",
    "\t\tTODO:\n",
    "\t\t1. keep more features\n",
    "\t\t2. merge train and test, then use one-hot, finally split back into train and test\n",
    "\t\t'''\n",
    "\t\tpass\n",
    "\n",
    "\tdef standardize(self):\n",
    "\t\tfrom sklearn.preprocessing import StandardScaler\n",
    "\t\tss = StandardScaler()\n",
    "\t\tself.train_x = ss.fit_transform(self.train_x)\n",
    "\t\tself.test_x = ss.fit_transform(self.test_x)\n",
    "\n",
    "\tdef get_dataset(self):\n",
    "\t\tself.dataset = Dataset(self.train_x, self.train_y, self.test_x, self.test_y)\n",
    "\t\treturn self.dataset\n",
    "\n",
    "def test1():\n",
    "\t'''\n",
    "\tperceptron with sklearn\n",
    "\t'''\n",
    "\tfe = FeatureEngineer()\n",
    "\tfe.filter1()\n",
    "\tfe.standardize()\n",
    "\tdataset = fe.get_dataset()\n",
    "\n",
    "\tfrom sklearn.linear_model import Perceptron\n",
    "\tperceptron = Perceptron(max_iter = 1, eta0 = 0.01, tol = 1e-3, random_state = 0)\n",
    "\tperceptron.fit(dataset.train_x, dataset.train_y)\n",
    "\tpred_y = perceptron.predict(dataset.test_x).tolist()\n",
    "\tdataset.pred_y = pred_y\n",
    "\n",
    "\tfrom sklearn.metrics import accuracy_score\n",
    "\tprint(\"准确率: \", accuracy_score(dataset.test_y, dataset.pred_y))\n",
    "\n",
    "class Perceptron(object):\n",
    "\t'''\n",
    "\tTODO[done]\n",
    "\t实现 Perceptron\n",
    "\t'''\n",
    "\tdef __init__(self, dataset, learning_rate=0.001):\n",
    "\t\tself.dataset = dataset\n",
    "\t\tself.row = dataset.train_x.shape[0]\n",
    "\t\tself.col = dataset.train_x.shape[1]\n",
    "\t\tself.w = np.zeros(self.col)\n",
    "\t\tself.b = np.zeros(1)\n",
    "\t\tself.learning_rate = learning_rate\n",
    "\n",
    "\tdef update_w(self, y, x):\n",
    "\t\teta = self.learning_rate\n",
    "\t\t# print('w: ', self.w)\n",
    "\t\tfor i in range(self.col):\n",
    "\t\t\tself.w[i] += eta * x[i] * y\n",
    "\t\t# print('w: ', self.w)\n",
    "\n",
    "\tdef update_b(self, y):\n",
    "\t\teta = self.learning_rate\n",
    "\t\t# print('b: ', self.b)\n",
    "\t\tself.b += eta * y\n",
    "\t\t# print('b: ', self.b)\n",
    "\n",
    "\tdef sign(self, x):\n",
    "\t\tres = 0\n",
    "\t\tb = self.b\n",
    "\t\tw = self.w\n",
    "\t\tfor i in range(self.col):\n",
    "\t\t\tres += w[i] * x[i]\n",
    "\t\tres += b\n",
    "\t\tif res >= 0:\n",
    "\t\t\treturn 1\n",
    "\t\telse:\n",
    "\t\t\treturn -1\n",
    "\n",
    "\tdef judge(self, y, b, x=[], w=[]):\n",
    "\t\tres = 0\n",
    "\t\tfor i in range(self.col):\n",
    "\t\t\tres += w[i] * x[i]\n",
    "\t\tres = (res + b) * y\n",
    "\t\treturn res\n",
    "\n",
    "\tdef fit(self):\n",
    "\t\t# https://docs.python.org/3.5/library/random.html\n",
    "\t\timport random\n",
    "\t\trandom.seed(0)\n",
    "\t\tepoch = 100\n",
    "\t\trow = self.row\n",
    "\t\tfor e in range(epoch):\n",
    "\t\t\ti = random.randint(0, row)\n",
    "\t\t\tb = self.b\n",
    "\t\t\tw = self.w\n",
    "\t\t\tx = self.dataset.train_x[i]\n",
    "\t\t\ty = self.dataset.train_y[i]\n",
    "\t\t\tres = self.judge(y, b, x, w)\n",
    "\t\t\t# print('res: ', res)\n",
    "\t\t\tif res <= 0:\n",
    "\t\t\t\tself.update_w(y, x)\n",
    "\t\t\t\tself.update_b(y)\n",
    "\n",
    "\tdef predict(self):\n",
    "\t\ttest_x = self.dataset.test_x\n",
    "\t\trow = test_x.shape[0]\n",
    "\t\tpred_y = np.zeros(row)\n",
    "\t\tfor i in range(row):\n",
    "\t\t\tpred_y[i] = self.sign(test_x[i])\n",
    "\t\t\t# pred_y[i] = -1 # cheat with accuracy of 75.22%\n",
    "\t\tself.dataset.pred_y = pred_y\n",
    "\n",
    "\tdef cheat_predict(self):\n",
    "\t\t'''\n",
    "\t\tYou will get a cheat-accuracy of 75.22%\n",
    "\t\t'''\n",
    "\t\ttest_x = self.dataset.test_x\n",
    "\t\trow = test_x.shape[0]\n",
    "\t\tpred_y = np.zeros(row)\n",
    "\t\tfor i in range(row):\n",
    "\t\t\tpred_y[i] = -1\n",
    "\t\tself.dataset.pred_y = pred_y\n",
    "\n",
    "\tdef get_accuracy(self):\n",
    "\t\tfrom sklearn.metrics import accuracy_score\n",
    "\t\tprint(\"准确率: \", accuracy_score(self.dataset.test_y, self.dataset.pred_y))\n",
    "\n",
    "def test2():\n",
    "\t'''\n",
    "\tperceptron from scratch\n",
    "\t'''\n",
    "\tfe = FeatureEngineer()\n",
    "\tfe.filter1()\n",
    "\tfe.standardize()\n",
    "\tdataset = fe.get_dataset()\n",
    "\n",
    "\tperceptron = Perceptron(dataset, 1e-3)\n",
    "\tperceptron.fit()\n",
    "\tperceptron.predict()\n",
    "\tperceptron.get_accuracy()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\t# test1()\n",
    "\ttest2()\n",
    "\n",
    "\n",
    "def annotation_and_TODO():\n",
    "\t'''\n",
    "\t结果分析:\n",
    "\t虽然丢掉了很多数据，但是准确率和原来没有丢掉数据相比，并没有太大变化(甚至有提升)\n",
    "\t通过阅读 adult.names 文档可以知道, 训练集的标签分布是【不均匀的】, 0 的比例是 76.07%, 1 的比例是 23.93%\n",
    "\t测试集的标签也有类似的分布, 0 的比例是 75.22%, 1 的比例是 24.78%\n",
    "\t与本次特征工程+模型给出的 77.12% 的准确率很接近\n",
    "\t也就是说, 如果一个模型 model 在任何时候都输出 0, 那这个 model 在测试集上的准确率也会有 75% 左右的准确率, 如 Perceptron.cheat_predict\n",
    "\t另外有一个奇怪的现象: 当训练迭代次数增加, 准确率反而会下降\n",
    "\n",
    "\t本次实验, 首要目的是熟悉过程, 接下来是进一步的改进\n",
    "\t\n",
    "\tTODO1: 实现 Perceptron\n",
    "\t    [done], 在 random.seed(0) 的情况下, 使用 100 次 SGD, 可以达到 77% 左右的准确率\n",
    "\tTODO2: filter1\n",
    "\tTODO3: filter2\n",
    "\t'''\n",
    "\tpass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
